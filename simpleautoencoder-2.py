# -*- coding: utf-8 -*-
"""SimpleAutoEncoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T5rT54csMkkMi7QDFVLh8MIJu4J74mQl
"""

import numpy as np
import tensorflow as tf
import keras
from keras.datasets import mnist
from keras.models import Model, Sequential
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape
from keras import regularizers

# Loads the training and test data sets (ignoring class labels)
(x_train, _), (x_test, _) = mnist.load_data() # mnnist_data= no_of_images*28*28; 3d matrix
#print(x_train.shape)   #(60000, 28, 28)
#print(x_test.shape)    #(10000, 28, 28)

# import matplotlib.pyplot as plt
# %matplotlib inline
#  plt.imshow(x_train[1])

# import pylab

subplot(2,1,1)
xticks([]), yticks([])
title('subplot(2,1,1)')
imshow(x_train[1])

subplot(2,1,2)
xticks([]), yticks([])
title('subplot(2,1,2)')
imshow(x_train[0],'-r')

# print(x_train)
# Scales the training and test data to range between 0 and 1.
max_value = (x_train.max())
print(max_value)
# print(x_train[1])
# print(x_train.astype('float32'));
x_train = x_train / max_value
x_test = x_test/ max_value

x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:]))) #?
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

(x_train.shape, x_test.shape)

# input dimension = 784
input_dim = x_train.shape[1]
encoding_dim = 32

compression_factor = float(input_dim) / encoding_dim
print("Compression factor: %s" % compression_factor)

autoencoder = Sequential()

autoencoder.add(
    Dense(encoding_dim, input_shape=(input_dim,), activation='relu') #??
)
autoencoder.add(
    Dense(input_dim, activation='sigmoid')
)

autoencoder.summary()

input_img = Input(shape=(input_dim,))

encoder_layer = autoencoder.layers[0]
encoder = Model(input_img, encoder_layer(input_img))

encoder.summary()

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

num_images = 10
np.random.seed(42)
random_test_images = np.random.randint(x_test.shape[0], size=num_images)

encoded_imgs = encoder.predict(x_test)
decoded_imgs = autoencoder.predict(x_test)

plt.figure(figsize=(18, 4))

for i, image_idx in enumerate(random_test_images):
    # plot original image
    ax = plt.subplot(3, num_images, i + 1)
    plt.imshow(x_test[image_idx].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    # plot encoded image
    ax = plt.subplot(3, num_images, num_images + i + 1)
    plt.imshow(encoded_imgs[image_idx].reshape(8, 4))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # plot reconstructed image
    ax = plt.subplot(3, num_images, 2*num_images + i + 1)
    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

